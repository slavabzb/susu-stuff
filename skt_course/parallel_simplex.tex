\subsection{Распараллеливание симплекс-метода}
\label{parallel_simplex}

Существующие подходы к распараллеливанию симплекс-метода и ему подобных удобно классифицировать по виду симплекс-метода и по использованию разреженных типов данных. Такая классификация позитивно коррелирует с практической ценностью реализации в контексте решения ЗЛП и негативно с успешностью этих подходов в достигнутом ускорении.

Некоторые из рассматриваемых ниже схем предлагают неплохое ускорение относительно эффективных последовательных решателей своего времени. Другие только кажутся неэффективными в свете последовательного обратного симплекса, который к тому моменту либо был малоизвестен, либо был разработан впоследствии. Такие случаи определяются ниже, чтобы подчеркнуть, что в результате огромного увеличения эффективности последовательного обратного симплекс-метода (как во время исследований в области распараллеливания симплекса, так и после) проблема разработки практического параллельного симплекс-решателя стала очень актуальной.

\subsubsection{Параллельный симплекс-метод с использованием алгебры плотных матриц}
\label{parallel_simplex_dense}

Стандартный и обратный симплекс-методы с использованием алгебры плотных матриц реализовывались неоднократно. Простота обычных структур данных и потенциал достичь линейного ускорения делают их привлекательными для применения в параллельных вычислениях. Хотя при решении общих разреженных ЗЛП больших размерностей такие реализации малоэффективны, поскольку они могут соперничать с эффективными последовательными реализациями обратного симплекс-метода, использующими разреженные структуры, только при подключении значительного числа процессоров.

Первые работы в этом направлении ограничиваются обсуждением схем распределения данных и коммуникации; реализации ограничиваются небольшим числом процессов на ЭВМ с распределенной памятью (краткие обзоры даются в \cite{Zenios1989, Luo1991}, примеры других ранних работ можно найти в \cite{Finkel1987, Boffley1989, Babaev1991, Agrawal1989}). В одной из относительно ранних работ \cite{Stunkel1988}, в которой были реализованы обычный и обратный симплекс-методы на 16-процессорном Intel hypercube, достигнутое ускорение варьируется от 8 до 12 для небольших задач из библиотеки Netlib. В \cite{Cvetanovic1991} сообщается о 12-кратном ускорении при решении двух небольших ЗЛП с использованием обычного симлекс-метода на 16-процессорной ЭВМ с \textit{общей разделяемой памятью}. Также были случаи получения более чем 12-кратного ускорения \cite{Luo1992}.

В \cite{Eckstein1995} разработаны параллельный обычный и обратный симплекс-методы с применением метода наиболее крутого ребра \cite{Goldfarb1977} и протестированы на машинах Connection Machine CM-2 и CM-5 с массовым параллелизмом. Решая некоторые ЗЛП средней размерности из Netlib и очень плотные задачи машинного обучения, ускорение между 1.6 и 1.8 было достигнуто только при удвоении числа процессоров. В \cite{Thomadakis1996} также используется метод наиболее крутого ребра и обычный симплекс-метод на ЭВМ MasPar MP-1 и MP-2. Решая в основном случайно сгенерированные ЗЛП большой размерности, авторы достигали практически троекратного ускорения. Одной из более поздних работ по реализации параллельного обычного симплекс-метода с запуском на небольшом количестве процессоров является \cite{Yarmish2001}.

Работы по созданию параллельных реализаций обычного симплекс-метода с использованием алгебры плотных матриц для ЗЛП небольших размерностей продолжаются. Были представлены результаты реализации на 8 процессорах с 5-кратным ускорением при решении небольших случайных ЗЛП \cite{Badr2006}.

\subsubsection{Параллельный симплекс-метод с использованием алгебры разреженных матриц}
\label{parallel_simplex_sparse}

Особой сложностью в разработке действительно хорошего в практическом смысле параллельного симплекс-метода является применение эффективных техник работы с разреженными матрицами. Разработанный параллельный решатель будет конкурентноспособным по отношению к хорошей последовательной реализации только тогда, когда решение общих разреженных ЗЛП большой размерности будет затрагивать разумное число процессоров.

В период, когда распараллеливание симплекс-метода только начиналось и широко дискутировалось, практические параллельные методы факторизации и решения разреженных асимметричных СЛАУ были только на стадии становления. Как следствие, несмотря на то, что в симплекс-методе с плотными матрицами внедрение параллелизма проходило успешно, было распространено мнение, что использование разреженных матриц сильно ограничивает возможности распараллеливания (за исключением \texttt{PRICE}). Некоторых это наводило на мысль, что разработать хорошую параллельную реализацию невозможно в принципе. Но несмотря на преимущественно последовательную природу компонентов обратного симплекс метода, все еще существуют возможности применения параллелизма по задачам.

\subsubsection{Схема распараллеливания}
\label{parallel_simplex_scheme}

Рассмотрим следующий подход, использующий некоторые (но не все) возможности применения параллелизма по данным и по задачам к алгоритму обратного симплекс-метода с субоптимизацией\cite{Hall2012}. Рисунок~\ref{i:revised_parallel_schema} иллюстрирует идею.

\begin{figure}
\centering
\includegraphics[scale=0.3]{i/revised_parallel_schema.png} 
\caption{Прототип параллельной реализации обратного симплекс-метода с субоптимизацией\label{i:revised_parallel_schema}}
\end{figure}

\begin{table}
\centering
\begin{tabularx}{\linewidth}{lX}
\texttt{CHUZR}:                  & Из отношений~$\hat{b}_i/s_p$ для~$p=1,\ldots,m$ определить \\ 
& множество~$\mathcal{P}$ строк хороших кандидатов для вывода из базиса. \\
\texttt{BTRAN}:                  & Сформировать~$\pi^T_p=e^T_pB^{-1}$, $\forall p\in\mathcal{P}$.                                                                             \\        
\texttt{PRICE}:                  & Сформировать строку поворота~$\hat{a}^T_p=\pi^T_pN$, $\forall p\in\mathcal{P}$.                                                            \\
\multicolumn{2}{l}{\texttt{Цикл} \{младшие итерации\}}                                                                                    \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{CHUZR\_MI}: Из~$\hat{b}$ определить номер строки~$p\in\mathcal{P}$ хорошего} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{CHUZR\_MI}:} кандидата для вывода из базиса.} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{CHUZR\_MI}:} Если~$p$ не определен, то \texttt{Конец цикла} \{младшие итерации\}} \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{CHUZC}: Среди отношений~$\hat{c}_j/\hat{a}_{pj}$ определить номер столбца~$q$} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{CHUZC}:} хорошего кандидата для ввода в базис.} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{CHUZC}:} Обновить~$\hat{c}^T_N:=\hat{c}^T_N-\beta\hat{a}^T_p$, где~$\beta=\hat{c}_q/\hat{a}_{pq}$.} \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{UPDATE\_MI}: Обновить~$\mathcal{P}:=\mathcal{P}\textbackslash\{p\}$ и~$\hat{c}^T_N:=\hat{c}^T_N-\beta\hat{a}^T_p$, где~$\beta=\hat{c}_q/\hat{a}_{pq}$.} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{UPDATE\_MI}:} Обновить строки~$\hat{a}^T_P$ и~$\hat{b}_P$.} \\
\multicolumn{2}{l}{\texttt{Конец цикла} \{младшие итерации\}}                                                                                    \\
\multicolumn{2}{l}{\texttt{Для} \{каждого изменения базиса\} \texttt{выполнять}} \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{FTRAN1}: Сформировать~$\hat{a}_q=B^{-1}a_q$, где~$a_q$ -- столбец~$q$ матрицы~$A$.} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{FTRAN1}:} Обновить~$\hat{b}:=\hat{b}-\alpha\hat{a}_q$, где~$\alpha=\hat{b}_p/\hat{a}_{pq}$.} \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{FTRAN2}: Сформировать~$\tau=B^{-1}\hat{a}_q$.} \\
\multicolumn{2}{l}{\hspace*{1cm}\phantom{\texttt{FTRAN2}:} Обновить~$s_p$ для~$p=1,\ldots,m$.} \\

\multicolumn{2}{l}{\hspace*{1cm}\texttt{Если} \{рост в представлении~$B^{-1}$\}, \texttt{тогда}}                                                                                    \\
\multicolumn{2}{l}{\hspace*{1cm}\hspace*{1cm}\texttt{INVERT}: Сформировать новое представление~$B^{-1}$.}                                                     \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{иначе}}                                                                                                                                 \\
\multicolumn{2}{l}{\hspace*{2cm}\texttt{UPDATE}: Обновить представление~$B^{-1}$ в соответствии}                            \\
\multicolumn{2}{l}{\hspace*{2cm}\phantom{\texttt{UPDATE}:} с изменением базиса.} \\
\multicolumn{2}{l}{\hspace*{1cm}\texttt{конец если}} \\
\multicolumn{2}{l}{\texttt{Конец для}}
\end{tabularx}
\caption{Итерация обратного симплекс-метода с применением субоптимизации и метода наиболее крутого ребра}
\label{tb:revised_parallel}
\end{table}

Сначала относительно дешевая операция CHUZR выбора множества~$\mathcal{P}$ хороших кандидатов для вывода из базиса выполняется на одном ядре (таблица~\ref{tb:revised_parallel}). Затем, несколько операций BTRAN~($\pi^T_p=e^T_pB^{-1}$) и PRICE~($\hat{a}^T_p=\pi^T_pN$) для~$p\in\mathcal{P}$ распределяются между всеми ядрами. Поскольку малый цикл итераций обрабатывает только небольшую часть строк, операция CHUZR\_MI выполняется на одном ядре и не показана на рисунке~\ref{i:revised_parallel_schema}. Выбор вводимой колонки выполняется в CHUZC относительно просто, поэтому также не распределяется. Малый цикл замыкает операция UPDATE\_MI, в которой параллельное обновление данных в строках таблицы обратного симплекс-метода (оставшиеся кандидаты) и альтернативных издержек~$\hat{c}^T_N$ выполняется на всех доступных ядрах. Простое обновление~$\hat{b}_P$ выполняется на одном ядре операцией CHUZR\_MI. После завершения малого цикла итераций, операции FTRAN~$\hat{a}=B^{-1}a_q$ и~$\tau=B^{-1}\hat{a}_q$ для каждого изменения базиса распределяется между всеми ядрами. Если необходимо, INVERT выполняется последовательно, без перекрытия любых других вычислений.
